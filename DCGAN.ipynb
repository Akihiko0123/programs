{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNvAM6+cTwLYJMPamOfJdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akihiko0123/programs/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrfaPTwLpunV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ed8d00-5b9a-4f6e-b755-9ec5b193bb85"
      },
      "source": [
        "pip install git+https://github.com/bstriner/keras-adversarial.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/bstriner/keras-adversarial.git\n",
            "  Cloning https://github.com/bstriner/keras-adversarial.git to /tmp/pip-req-build-4i7zn_lo\n",
            "  Running command git clone -q https://github.com/bstriner/keras-adversarial.git /tmp/pip-req-build-4i7zn_lo\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-adversarial==0.0.3) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (1.19.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adversarial==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-adversarial==0.0.3) (1.15.0)\n",
            "Building wheels for collected packages: keras-adversarial\n",
            "  Building wheel for keras-adversarial (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-adversarial: filename=keras_adversarial-0.0.3-py2.py3-none-any.whl size=14047 sha256=c0776cdf5f5df684e320e13d5c2d8e49b9b059f0ec2f8e737af9169dbf9c268f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yf7u20y4/wheels/f4/34/ba/6041a92244597803d1f8954d649e7899d011d46f33c02dc476\n",
            "Successfully built keras-adversarial\n",
            "Installing collected packages: keras-adversarial\n",
            "Successfully installed keras-adversarial-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iTY-U_ZzlX1C",
        "outputId": "20854e3d-fbba-4cf2-a8a8-99f2f79efbd5"
      },
      "source": [
        "import matplotlib as mpl\r\n",
        "\r\n",
        "# This line allows mpl to run with no DISPLAY defined\r\n",
        "mpl.use('Agg')\r\n",
        "\r\n",
        "from keras.layers import Flatten, Dropout, LeakyReLU, Input, Activation,Dense,BatchNormalization\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers.convolutional import UpSampling2D,Conv2D\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.datasets import mnist\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import keras.backend as K\r\n",
        "from keras_adversarial.image_grid_callback import ImageGridCallback\r\n",
        "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\r\n",
        "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\r\n",
        "from image_utilsx import dim_ordering_fix, dim_ordering_input, dim_ordering_reshape, dim_ordering_unfix\r\n",
        "\r\n",
        "\r\n",
        "def leaky_relu(x):\r\n",
        "    return K.relu(x, 0.2)\r\n",
        "\r\n",
        "\r\n",
        "def model_generator():\r\n",
        "    nch = 256\r\n",
        "    g_input = Input(shape=[100])\r\n",
        "    H = Dense(nch * 14 * 14)(g_input)\r\n",
        "    H = BatchNormalization(mode=2)(H)\r\n",
        "    H = Activation('relu')(H)\r\n",
        "    H = dim_ordering_reshape(nch, 14)(H)\r\n",
        "    H = UpSampling2D(size=(2, 2))(H)\r\n",
        "    H = Conv2D(int(nch / 2), 3, 3, border_mode='same')(H)\r\n",
        "    H = BatchNormalization(mode=2, axis=1)(H)\r\n",
        "    H = Activation('relu')(H)\r\n",
        "    H = Conv2D(int(nch / 4), 3, 3, border_mode='same')(H)\r\n",
        "    H = BatchNormalization(mode=2, axis=1)(H)\r\n",
        "    H = Activation('relu')(H)\r\n",
        "    H = Conv2D(1, 1, 1, border_mode='same')(H)\r\n",
        "    g_V = Activation('sigmoid')(H)\r\n",
        "    return Model(g_input, g_V)\r\n",
        "\r\n",
        "\r\n",
        "def model_discriminator(input_shape=(1, 28, 28), dropout_rate=0.5):\r\n",
        "    d_input = dim_ordering_input(input_shape, name=\"input_x\")\r\n",
        "    nch = 512\r\n",
        "    # nch = 128\r\n",
        "    H = Conv2D(int(nch / 2), 5, 5, subsample=(2, 2), border_mode='same', activation='relu')(d_input)\r\n",
        "    H = LeakyReLU(0.2)(H)\r\n",
        "    H = Dropout(dropout_rate)(H)\r\n",
        "    H = Conv2D(nch, 5, 5, subsample=(2, 2), border_mode='same', activation='relu')(H)\r\n",
        "    H = LeakyReLU(0.2)(H)\r\n",
        "    H = Dropout(dropout_rate)(H)\r\n",
        "    H = Flatten()(H)\r\n",
        "    H = Dense(int(nch / 2))(H)\r\n",
        "    H = LeakyReLU(0.2)(H)\r\n",
        "    H = Dropout(dropout_rate)(H)\r\n",
        "    d_V = Dense(1, activation='sigmoid')(H)\r\n",
        "    return Model(d_input, d_V)\r\n",
        "\r\n",
        "\r\n",
        "def mnist_process(x):\r\n",
        "    x = x.astype(np.float32) / 255.0\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def mnist_data():\r\n",
        "    (xtrain, ytrain), (xtest, ytest) = mnist.load_data()\r\n",
        "    return mnist_process(xtrain), mnist_process(xtest)\r\n",
        "\r\n",
        "\r\n",
        "def generator_sampler(latent_dim, generator):\r\n",
        "    def fun():\r\n",
        "        zsamples = np.random.normal(size=(10 * 10, latent_dim))\r\n",
        "        gen = dim_ordering_unfix(generator.predict(zsamples))\r\n",
        "        return gen.reshape((10, 10, 28, 28))\r\n",
        "\r\n",
        "    return fun\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # z \\in R^100\r\n",
        "    latent_dim = 100\r\n",
        "    # x \\in R^{28x28}\r\n",
        "    input_shape = (1, 28, 28)\r\n",
        "\r\n",
        "    # generator (z -> x)\r\n",
        "    generator = model_generator()\r\n",
        "    # discriminator (x -> y)\r\n",
        "    discriminator = model_discriminator(input_shape=input_shape)\r\n",
        "    # gan (x - > yfake, yreal), z generated on GPU\r\n",
        "    gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))\r\n",
        "\r\n",
        "    # print summary of models\r\n",
        "    generator.summary()\r\n",
        "    discriminator.summary()\r\n",
        "    gan.summary()\r\n",
        "\r\n",
        "    # build adversarial model\r\n",
        "    model = AdversarialModel(base_model=gan,\r\n",
        "                             player_params=[generator.trainable_weights, discriminator.trainable_weights],\r\n",
        "                             player_names=[\"generator\", \"discriminator\"])\r\n",
        "    model.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(),\r\n",
        "                              player_optimizers=[Adam(1e-4, decay=1e-4), Adam(1e-3, decay=1e-4)],\r\n",
        "                              loss='binary_crossentropy')\r\n",
        "\r\n",
        "    # train model\r\n",
        "    generator_cb = ImageGridCallback(\"output/gan_convolutional/epoch-{:03d}.png\",\r\n",
        "                                     generator_sampler(latent_dim, generator))\r\n",
        "\r\n",
        "    xtrain, xtest = mnist_data()\r\n",
        "    xtrain = dim_ordering_fix(xtrain.reshape((-1, 1, 28, 28)))\r\n",
        "    xtest = dim_ordering_fix(xtest.reshape((-1, 1, 28, 28)))\r\n",
        "    y = gan_targets(xtrain.shape[0])\r\n",
        "    ytest = gan_targets(xtest.shape[0])\r\n",
        "    history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest), callbacks=[generator_cb], nb_epoch=10,\r\n",
        "                        batch_size=32)\r\n",
        "    df = pd.DataFrame(history.history)\r\n",
        "    df.to_csv(\"output/gan_convolutional/history.csv\")\r\n",
        "\r\n",
        "    generator.save(\"output/gan_convolutional/generator.h5\")\r\n",
        "    discriminator.save(\"output/gan_convolutional/discriminator.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:321: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:634: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:491: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1506: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:73: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1047: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2934: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_1 (InputLayer)             (None, 100)           0                                            \n",
            "____________________________________________________________________________________________________\n",
            "dense_1 (Dense)                  (None, 50176)         5067776     input_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "batchnormalization_1 (BatchNorma (None, 50176)         200704      dense_1[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "activation_1 (Activation)        (None, 50176)         0           batchnormalization_1[0][0]       \n",
            "____________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)              (None, 14, 14, 256)   0           activation_1[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "upsampling2d_1 (UpSampling2D)    (None, 28, 28, 256)   0           reshape_1[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "convolution2d_1 (Convolution2D)  (None, 28, 28, 128)   295040      upsampling2d_1[0][0]             \n",
            "____________________________________________________________________________________________________\n",
            "batchnormalization_2 (BatchNorma (None, 28, 28, 128)   112         convolution2d_1[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "activation_2 (Activation)        (None, 28, 28, 128)   0           batchnormalization_2[0][0]       \n",
            "____________________________________________________________________________________________________\n",
            "convolution2d_2 (Convolution2D)  (None, 28, 28, 64)    73792       activation_2[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "batchnormalization_3 (BatchNorma (None, 28, 28, 64)    112         convolution2d_2[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "activation_3 (Activation)        (None, 28, 28, 64)    0           batchnormalization_3[0][0]       \n",
            "____________________________________________________________________________________________________\n",
            "convolution2d_3 (Convolution2D)  (None, 28, 28, 1)     65          activation_3[0][0]               \n",
            "____________________________________________________________________________________________________\n",
            "activation_4 (Activation)        (None, 28, 28, 1)     0           convolution2d_3[0][0]            \n",
            "====================================================================================================\n",
            "Total params: 5,637,601\n",
            "Trainable params: 5,537,137\n",
            "Non-trainable params: 100,464\n",
            "____________________________________________________________________________________________________\n",
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_x (InputLayer)             (None, 28, 28, 1)     0                                            \n",
            "____________________________________________________________________________________________________\n",
            "convolution2d_4 (Convolution2D)  (None, 14, 14, 256)   6656        input_x[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "leakyrelu_1 (LeakyReLU)          (None, 14, 14, 256)   0           convolution2d_4[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)              (None, 14, 14, 256)   0           leakyrelu_1[0][0]                \n",
            "____________________________________________________________________________________________________\n",
            "convolution2d_5 (Convolution2D)  (None, 7, 7, 512)     3277312     dropout_1[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "leakyrelu_2 (LeakyReLU)          (None, 7, 7, 512)     0           convolution2d_5[0][0]            \n",
            "____________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)              (None, 7, 7, 512)     0           leakyrelu_2[0][0]                \n",
            "____________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)              (None, 25088)         0           dropout_2[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "dense_2 (Dense)                  (None, 256)           6422784     flatten_1[0][0]                  \n",
            "____________________________________________________________________________________________________\n",
            "leakyrelu_3 (LeakyReLU)          (None, 256)           0           dense_2[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)              (None, 256)           0           leakyrelu_3[0][0]                \n",
            "____________________________________________________________________________________________________\n",
            "dense_3 (Dense)                  (None, 1)             257         dropout_3[0][0]                  \n",
            "====================================================================================================\n",
            "Total params: 9,707,009\n",
            "Trainable params: 9,707,009\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n",
            "____________________________________________________________________________________________________\n",
            "Layer (type)                     Output Shape          Param #     Connected to                     \n",
            "====================================================================================================\n",
            "input_x (InputLayer)             (None, 28, 28, 1)     0                                            \n",
            "____________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)                (None, 100)           0           input_x[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "gan (Model)                      [(None, 1), (None, 1) 15344610    lambda_1[0][0]                   \n",
            "                                                                   input_x[0][0]                    \n",
            "____________________________________________________________________________________________________\n",
            "yfake (Activation)               (None, 1)             0           gan[1][0]                        \n",
            "____________________________________________________________________________________________________\n",
            "yreal (Activation)               (None, 1)             0           gan[1][1]                        \n",
            "====================================================================================================\n",
            "Total params: 15,344,610\n",
            "Trainable params: 15,244,146\n",
            "Non-trainable params: 100,464\n",
            "____________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:658: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2446: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.pkl.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:740: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "27936/60000 [============>.................] - ETA: 3732s - loss: 31.5774 - generator_loss: 31.5435 - generator_yfake_loss: 15.7670 - generator_yreal_loss: 15.7765 - discriminator_loss: 0.0339 - discriminator_yfake_loss: 0.0221 - discriminator_yreal_loss: 0.0117"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-948f875048cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest), callbacks=[generator_cb], nb_epoch=10,\n\u001b[0;32m--> 116\u001b[0;31m                         batch_size=32)\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/gan_convolutional/history.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2h90t_3qNyw",
        "outputId": "a09a8387-cb25-4d8e-c2f0-08ca29f48ea9"
      },
      "source": [
        "pip install image_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: image_utils in /usr/local/lib/python3.6/dist-packages (0.1.6)\n",
            "Requirement already satisfied: python-cephlibs in /usr/local/lib/python3.6/dist-packages (from image_utils) (0.94.5.post1)\n",
            "Requirement already satisfied: oslo.utils in /usr/local/lib/python3.6/dist-packages (from image_utils) (4.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from image_utils) (1.15.0)\n",
            "Requirement already satisfied: progressbar>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from image_utils) (2.5)\n",
            "Requirement already satisfied: pbr in /usr/local/lib/python3.6/dist-packages (from image_utils) (5.5.1)\n",
            "Requirement already satisfied: pytz>=2013.6 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (2018.9)\n",
            "Requirement already satisfied: netifaces>=0.10.4 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (0.10.9)\n",
            "Requirement already satisfied: oslo.i18n>=3.15.3 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (5.0.1)\n",
            "Requirement already satisfied: netaddr>=0.7.18 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (0.8.0)\n",
            "Requirement already satisfied: iso8601>=0.1.11 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (0.1.13)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (2.4.7)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (20.8)\n",
            "Requirement already satisfied: debtcollector>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from oslo.utils->image_utils) (2.2.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from netaddr>=0.7.18->oslo.utils->image_utils) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from debtcollector>=1.2.0->oslo.utils->image_utils) (1.12.1)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.7\"->netaddr>=0.7.18->oslo.utils->image_utils) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gFOu_mXs1y-",
        "outputId": "bb4158a8-de8e-4acc-9451-1faf405e178b"
      },
      "source": [
        "image_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'image_utils' from '/usr/local/lib/python3.6/dist-packages/image_utils/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "DDhAUtw2pFN1",
        "outputId": "5cb4f2c3-aba7-41a4-fe6c-6f5828da7d94"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 82kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (51.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-tFaD00mJG_",
        "outputId": "0210bcc0-e22b-4cfe-c106-d9f5d2f6a874"
      },
      "source": [
        "import keras\r\n",
        "import tensorflow\r\n",
        "print(keras.__version__)\r\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.3\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Gti8LYmKqt"
      },
      "source": [
        "pip install keras==2.4.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzdY7J3dDFyi"
      },
      "source": [
        "pip install tensorflow==2.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pamiu0QDo8At",
        "outputId": "121788f5-6648-45f5-f4e8-bd7e2b692ba9"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk6wYAvbt6Rm"
      },
      "source": [
        "import sys\r\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEIZOYoTv_J2"
      },
      "source": [
        "import image_utilsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "YAjbbWvExY1s",
        "outputId": "19e77521-4091-41bf-9460-253e56162b5b"
      },
      "source": [
        "pip install keras==1.2.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==1.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/3e/9926ce5c678b7a7978724a2ecf24857d89a415d152b8d3443e6d45c228b2/Keras-1.2.2.tar.gz (175kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 112kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 122kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 163kB 10.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 174kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (1.0.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==1.2.2) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.2.2) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==1.2.2) (1.19.4)\n",
            "Building wheels for collected packages: keras\n",
            "  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras: filename=Keras-1.2.2-cp36-none-any.whl size=209603 sha256=61e7ad9ee47a8033d8685bca70435e955075e89afe6b87df856eaeee22773fc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/07/cf/b32db0a8d243b2fd6759d5d7cb650aa20670b2b740209cbf7e\n",
            "Successfully built keras\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.1.3.1 has requirement keras>=2.0.0, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-1.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "CKcPkxne1AuX",
        "outputId": "34e1810d-387c-40d8-f9ea-7904b04ab703"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement keras>=2.0.0, but you'll have keras 1.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qCzQrz16yUWJ",
        "outputId": "07b27d58-b27a-432f-d727-8ed4464336b1"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6zPBcXh0DXB",
        "outputId": "edf3e621-0a73-491c-85cc-38c98f7882a6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan  6 13:16:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3mMCEiG3Fd7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}